<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>Moving from apt to dnf package management</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/24/move-apt-dnf-package-management" /><author><name>Bob Reselman</name></author><id>7989058e-2a55-483d-926e-36cbd5eff3bf</id><updated>2022-10-07T07:00:00Z</updated><published>2022-10-07T07:00:00Z</published><summary type="html">&lt;p&gt;A package manager makes it simple to install &lt;a href="https://developers.redhat.com/topics/linux"&gt;GNU/Linux&lt;/a&gt; applications on a local computer. Before package management became commonplace, installing applications was a tedious, error-prone undertaking. The ease a package manager brings to installing an application on a Linux computer has been a major factor contributing to the widespread adoption of Linux as a mainstream operating system for both business and home users.&lt;/p&gt; &lt;p&gt;Package management under Linux is divided, however. Two major systems co-exist:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The APT package management system for Debian and its many derivatives, notably Ubuntu. Packages are marked with the &lt;code&gt;.deb&lt;/code&gt; suffix and are managed through the &lt;code&gt;apt&lt;/code&gt; command-line interface (CLI).&lt;/li&gt; &lt;li&gt;The RPM package management system for &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; and its derivatives, notably Fedora and CentOS Stream. Packages are marked with the &lt;code&gt;.rpm&lt;/code&gt; suffix and are managed through the &lt;code&gt;dnf&lt;/code&gt; CLI.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This article is for developers who are currently using Debian-based systems and are familiar with APT, but want to start using a system in the Red Hat Enterprise Linux family. The article explains the similarities and differences between APT and RPM. I show how to execute specific, commonplace package management tasks using each system.&lt;/p&gt; &lt;h2&gt;Understanding apt, dnf, and yum&lt;/h2&gt; &lt;p&gt;Debian users are accustomed to managing their packages via the &lt;code&gt;apt&lt;/code&gt; command. Switching to the current RPM tool, &lt;code&gt;dnf&lt;/code&gt;, is the topic of this article.&lt;/p&gt; &lt;p&gt;You might also have seen references to a &lt;code&gt;yum&lt;/code&gt; command. Both &lt;code&gt;dnf&lt;/code&gt; and &lt;code&gt;yum&lt;/code&gt; are command-line utilities that work with RPM packages. Red Hat originally released and depended on &lt;code&gt;yum&lt;/code&gt;, which is an acronym for &lt;em&gt;Yellowdog Updater, Modified&lt;/em&gt;. &lt;code&gt;dnf&lt;/code&gt;, an abbreviation for &lt;em&gt;dandified yum&lt;/em&gt;, is the follow-up technology—based on &lt;code&gt;yum&lt;/code&gt;, as the name implies.&lt;/p&gt; &lt;p&gt;Today, &lt;code&gt;dnf&lt;/code&gt; is the default package management utility for Red Hat Enterprise Linux, Fedora, and CentOS Stream, and has been so since Fedora 22, CentOS 8, and Red Hat Enterprise Linux 8, respectively. &lt;code&gt;yum&lt;/code&gt; has been deprecated as the default package manager in the Red Hat family of distributions, so while &lt;code&gt;yum&lt;/code&gt; commands currently work, it's best to use just &lt;code&gt;dnf&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Understanding package discovery and installation&lt;/h2&gt; &lt;p&gt;The pattern for finding and installing a Linux package is essentially the same whether you're using &lt;code&gt;apt&lt;/code&gt; or &lt;code&gt;dnf&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;When you execute a command to install a package, the package manager looks at configuration files on the local machine to determine the location of a repository that has a given package on the internet. Then the installation command downloads the package along with its dependencies from the internet. Finally, the package manager installs and configures the application on the local machine. Figure 1 illustrates the process.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/patt.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/patt.png?itok=RGemPlHO" width="1111" height="602" alt="A package manager gets information from the local machine to retrieve a package from a repository." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: A package manager gets information from the local machine to retrieve a package from a repository. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Although the basic installation process is similar for both the RPM and APT package managers, there are distinctions when it comes to implementation. Besides the commands used, there's a bit of difference in the way these commands consult files to find and install packages.&lt;/p&gt; &lt;p&gt;When you invoke a package manager's installation command, the package manager first looks to see whether the package of interest is present and already installed. APT looks in the &lt;code&gt;/var/cache/apt/archives&lt;/code&gt; directory for the presence of the package's &lt;code&gt;.deb&lt;/code&gt; file. Under RPM, the package manager inspects the directories in &lt;code&gt;/var/cache/dnf/&lt;/code&gt; for a package's &lt;code&gt;.rpm&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;If the package's &lt;code&gt;.deb&lt;/code&gt; or &lt;code&gt;.rpm&lt;/code&gt; file is not present, the installer inspects files that describe the locations of repositories on the internet. In some cases, these files can report the packages that are stored in a particular repository as well. Under APT, the information is stored in the file &lt;code&gt;/etc/apt/sources.list &lt;/code&gt;or in &lt;code&gt;.list&lt;/code&gt; files in the directory &lt;code&gt;/etc/apt/sources.list.d&lt;/code&gt;. Under RPM, repository details are stored in &lt;code&gt;.xml&lt;/code&gt; files or compressed &lt;code&gt;.solvx&lt;/code&gt; files in the cache directory &lt;code&gt;/var/cache/dnf/&lt;/code&gt;. Also, general information about a repository is stored in &lt;code&gt;.repo&lt;/code&gt; files in the directory &lt;code&gt;/etc/yum.repos.d&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;After discovering information about a package and repository, the installer goes to a remote repository to find and install the package. In some cases, the installer might have to go to a number of remote repositories looking for a package. Should the installer not find a package of interest, the package manager reports an error.&lt;/p&gt; &lt;p&gt;Thus, the overall pattern for package discovery and installation for APT and RPM is similar. The difference is in the CLI tools used. The structure and contents of the file system used by the package installer on the local computer differ as well.&lt;/p&gt; &lt;p&gt;Most users migrating from Debian's &lt;code&gt;apt&lt;/code&gt; to RPM's &lt;code&gt;dnf&lt;/code&gt; never have to concern themselves with the difference between the internals of the APT and RPM package managers. Low-level operations have been abstracted away by the CLI tools.&lt;/p&gt; &lt;h2&gt;Executing commonplace commands&lt;/h2&gt; &lt;p&gt;In most cases, the main concern of developers migrating from &lt;code&gt;apt&lt;/code&gt; to &lt;code&gt;dnf&lt;/code&gt; is installing, removing, and updating packages, which we'll cover in this section. But first, I'll show you how to add a repository to search and how to list packages and known repositories.&lt;/p&gt; &lt;h3&gt;Adding a repository for the package manager to search&lt;/h3&gt; &lt;p&gt;To install a package on your computer, the CLI tool needs to know where the repositories containing the packages are. Typically, when you first set up your computer, whether it's running an operating system from the Debian family or the Red Hat Enterprise Linux family, information about the basic repositories that host the usual packages for the given operating system is included in the OS by default. However, there might be times when you need to search other repositories. This section shows the commands for adding information about a repository to a local computer.&lt;/p&gt; &lt;p&gt;To add information about a repository to a computer running Debian, Ubuntu, etc., enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# add-apt-repository &lt;repository identification information&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For example, the following command installs information for the MongoDB database on a  Debian machine:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo add-apt-repository 'deb [arch=amd64] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.0 multiverse'&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Commands that change system software must be entered as the superuser (root). Hence, these commands are prefixed with &lt;code&gt;sudo&lt;/code&gt;. I show the command prompt &lt;code&gt;#&lt;/code&gt; as a reminder that you must be running as root.&lt;/p&gt; &lt;p&gt;To add information about a repository to a computer running Red Hat Enterprise Linux, Fedora, or CentOS Stream, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# dnf config-manager --add-repo &lt;repo_url&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example installs the information about a mirror repository for CentOS 9 on the local machine:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf config-manager --add-repo="https://mirror.aarnet.edu.au/pub/centos/9"&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Updating the repository&lt;/h3&gt; &lt;p&gt;You also want to routinely make sure that current packages on the host computer are up to date. To update existing packages on Debian, run the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo apt update&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To update existing packages on a computer in the Red Hat Enterprise Linux family, execute the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf update&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Installing an application&lt;/h3&gt; &lt;p&gt;As mentioned previously, the pattern for installing packages on a host computer is similar in Debian and machines in the Red Hat Enterprise Linux family.&lt;/p&gt; &lt;p&gt;To install a package on a Debian machine, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo apt install &lt;package_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example installs the &lt;code&gt;jq&lt;/code&gt; utility for parsing and filtering JSON files on a Debian machine:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo apt install jq&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To install a package on a machine in the Red Hat Enterprise Linux family, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf install &lt;package_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example installs the &lt;code&gt;jq&lt;/code&gt; utility on a machine in the Red Hat Enterprise Linux family:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf install jq&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Removing an application&lt;/h3&gt; &lt;p&gt;The pattern for removing an application is similar for systems based on Debian and on Red Hat Enterprise Linux. The difference is the CLI tool used.&lt;/p&gt; &lt;p&gt;To remove a package on a Debian machine, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo apt remove &lt;package_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example removes the &lt;code&gt;jq&lt;/code&gt; utility from a Debian machine:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo apt remove jq&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To remove a package on Red Hat Enterprise Linux, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf remove &lt;package_name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example removes the &lt;code&gt;jq&lt;/code&gt; utility from a Red Hat Enterprise Linux machine:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo dnf remove jq&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Getting a list of packages installed on a host computer&lt;/h3&gt; &lt;p&gt;Listing the packages installed on a local machine can furnish useful information, particularly for auditing and system management.&lt;/p&gt; &lt;p&gt;To list all the packages installed on a machine running Debian, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ apt list&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example shows you how to use that command in conjunction with the &lt;code&gt;grep&lt;/code&gt; command to filter the results using a regular expression. The regular expression in this example saves only the lines that start with the characters &lt;code&gt;git&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ apt list | grep '^git'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following output shows a partial list of the results:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;git-annex-remote-rclone/focal,focal 0.6-1 all git-annex/focal 8.20200226-1 amd64 git-build-recipe/focal,focal 0.3.6 all git-buildpackage-rpm/focal,focal 0.9.19 all git-buildpackage/focal,focal 0.9.19 all git-cola/focal,focal 3.6-1 all git-crecord/focal,focal 20190217~git-1 all . . .&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To list the packages installed on a Red Hat Enterprise Linux machine, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ dnf list installed&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following example shows how to use that command to get a list of packages installed on a Red Hat Enterprise Linux machine and then pick out lines that start with &lt;code&gt;git&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ dnf list installed | grep '^git' &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The command produces the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;git.x86_64 2.35.3-1.fc35 @updates git-core.x86_64 2.35.3-1.fc35 @updates git-core-doc.noarch 2.35.3-1.fc35 @updates&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Getting a list of repositories known to a host computer&lt;/h3&gt; &lt;p&gt;Debian and the Red Hat Enterprise Linux family have different methods for listing repositories known to a given local computer.&lt;/p&gt; &lt;p&gt;Under a default installation of Debian, no single command has the logic to report known repositories. Instead, you have to finesse existing commands.&lt;/p&gt; &lt;p&gt;One way to list known repositories is to use the &lt;code&gt;apt-cache policy&lt;/code&gt; command to return the known repositories, as shown in the following example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ apt-cache policy |grep http |awk '{print $2 " " $3}' |sort -u&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We have seen &lt;code&gt;grep&lt;/code&gt; already. The &lt;code&gt;awk&lt;/code&gt; command that follows in the pipeline selects the second and third words of each line. The full command produces the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;http://dl.google.com/linux/chrome/deb stable/main http://ppa.launchpad.net/ansible/ansible/ubuntu focal/main http://security.ubuntu.com/ubuntu focal-security/main http://security.ubuntu.com/ubuntu focal-security/multiverse http://security.ubuntu.com/ubuntu focal-security/restricted http://security.ubuntu.com/ubuntu focal-security/universe http://us.archive.ubuntu.com/ubuntu focal-backports/main http://us.archive.ubuntu.com/ubuntu focal-backports/universe http://us.archive.ubuntu.com/ubuntu focal/main http://us.archive.ubuntu.com/ubuntu focal/multiverse http://us.archive.ubuntu.com/ubuntu focal/restricted http://us.archive.ubuntu.com/ubuntu focal/universe http://us.archive.ubuntu.com/ubuntu focal-updates/main http://us.archive.ubuntu.com/ubuntu focal-updates/multiverse http://us.archive.ubuntu.com/ubuntu focal-updates/restricted http://us.archive.ubuntu.com/ubuntu focal-updates/universe&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Another way to get a list of repositories is to inspect the entries that start with the characters &lt;code&gt;deb&lt;/code&gt; in the &lt;code&gt;etc/apt/sources.list&lt;/code&gt; files:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;# sudo grep -rhE ^deb /etc/apt/sources.list*&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The command produces the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;deb http://us.archive.ubuntu.com/ubuntu/ focal main restricted deb http://us.archive.ubuntu.com/ubuntu/ focal-updates main restricted deb http://us.archive.ubuntu.com/ubuntu/ focal universe deb http://us.archive.ubuntu.com/ubuntu/ focal-updates universe deb http://us.archive.ubuntu.com/ubuntu/ focal multiverse&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Things are easier when using &lt;code&gt;dnf&lt;/code&gt; in the Red Hat Enterprise Linux family. The &lt;code&gt;dnf repolist&lt;/code&gt; command lists the repositories known to the local machine.&lt;/p&gt; &lt;p&gt;The following example shows the result of running the &lt;code&gt;dnf repolist&lt;/code&gt; command. By default the command displays the two columns, &lt;code&gt;repo id&lt;/code&gt; and &lt;code&gt;repo name&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ dnf repolist&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The command produces the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;repo id repo name fedora Fedora 35 - x86_64 fedora-cisco-openh264 Fedora 35 openh264 (From Cisco) - x86_64 fedora-modular Fedora Modular 35 - x86_64 updates Fedora 35 - x86_64 - Updates updates-modular Fedora Modular 35 - x86_64 - Updates&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;A powerful and simple package management system&lt;/h2&gt; &lt;p&gt;Moving from Debian or Ubuntu to Red Hat Enterprise Linux, Fedora, or CentOS Stream requires some adjustment when it comes to working at the command line, but the transition can be easy.&lt;/p&gt; &lt;p&gt;The patterns for installing and removing applications are surprisingly similar, yet the command line tools are different. Ubuntu/Debian uses &lt;code&gt;apt&lt;/code&gt;. The Red Hat Enterprise Linux family uses &lt;code&gt;dnf&lt;/code&gt;. Both command line tools support similar subcommands, which is most evident with &lt;code&gt;apt install&lt;/code&gt; and &lt;code&gt;dnf install&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The techniques for keeping track of known repositories differ between operating systems. Fortunately for those moving to the Red Hat Enterprise Linux family, listing repositories is a lot easier because it involves only the &lt;code&gt;dnf repolist&lt;/code&gt; command. Listing repositories under Debian requires more work.&lt;/p&gt; &lt;p&gt;Learning the details of a new technology takes time. When transitioning from &lt;code&gt;apt&lt;/code&gt; to &lt;code&gt;dnf&lt;/code&gt;, you'll have to anticipate a learning curve. But the learning curve is not steep and you'll be up and running in no time.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/08/24/move-apt-dnf-package-management" title="Moving from apt to dnf package management"&gt;Moving from apt to dnf package management&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Bob Reselman</dc:creator><dc:date>2022-10-07T07:00:00Z</dc:date></entry><entry><title type="html">Jakarta MVC made simple</title><link rel="alternate" href="http://www.mastertheboss.com/java-ee/jakarta-ee/jakarta-mvc-made-simple/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java-ee/jakarta-ee/jakarta-mvc-made-simple/</id><updated>2022-10-06T16:50:36Z</updated><content type="html">This article discusses how to get started with Jakarta Model-View-Controller (MVC) to build Web applications using this well-known Web pattern in a Jakarta EE application. Model-View-Controller in a nutshell Model-View-Controller (MVC) is a popular pattern in Web frameworks to build HTML applications. In this framework, the model handles to the application’s data, the view handles ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">Kogito 1.28.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/10/kogito-1-28-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/10/kogito-1-28-0-released.html</id><updated>2022-10-06T09:25:20Z</updated><content type="html">We are glad to announce that the Kogito 1.28.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * You can now define Serverless Workflow custom type operations using addons. See the example . * Binary cloud event format is supported for any SmallRye connector which outputs CloudEvent Metadata (which includes HTTP and Kafka) BREAKING CHANGES * Metadata is no longer supported to define custom type serverless workflow functions. You should use type custom and operation prefix, as per . * HTTP listener on path / for cloud event consumption has been removed. You need to explicitly add http connector configuration to your project * To fix the failing application, you should add these two lines to application.properties  mp.messaging.incoming.kogito_incoming_stream.connector=quarkus-http             mp.messaging.incoming.kogito_incoming_stream.path=/ * As a consequence of this change, you can no longer consume CloudEvents both for http or kafka over the same SmallRye channel.  For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.23.0 artifacts are available at the . A detailed changelog for 1.28.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title>Why CSI drivers are essential in Kubernetes storage</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/10/06/csi-drivers-essential-kubernetes-storage" /><author><name>Fernando Lozano</name></author><id>a40aab57-d874-4edf-980f-a443d433f8ed</id><updated>2022-10-06T07:00:00Z</updated><published>2022-10-06T07:00:00Z</published><summary type="html">&lt;p&gt;This article is the third and final part of the series about Kubernetes storage concepts. I will explain how &lt;a href="https://kubernetes-csi.github.io/docs/"&gt;Container Storage Interface&lt;/a&gt; (CSI) drivers enable advanced storage features necessary for production environments and CI/CD pipelines. This article also underscores the need for storage products designed for Kubernetes versus storage designed for traditional physical and virtual data centers or Infrastructure-as-a-Service (IaaS) clouds.&lt;/p&gt; &lt;p&gt;Follow the series:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Part 1:&lt;/strong&gt;  &lt;a href="https://developers.redhat.com/articles/2022/09/16/how-kubernetes-improves-developer-agility"&gt;How Kubernetes improves developer agility&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The first part of this series explains why storage is important, even for developers who are developing stateless applications based on microservices architectures. I describe the unique needs of containerized applications. It also explains the role of Kubernetes in managing and providing storage volumes for applications running as pods.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Part 2:&lt;/strong&gt;  &lt;a href="https://developers.redhat.com/articles/2022/09/16/developers-guide-functions-kubernetes-storage"&gt;A developer’s guide to the functions of Kubernetes storage&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I explain why a developer's concept of volumes, persistent volume claims, and storage classes matter. It also describes the concepts of persistent volumes and storage provisioners and how they enable system administrators to manage storage for a Kubernetes cluster while, at the same time, offering developers self-service to storage.&lt;/p&gt; &lt;h2 id="csi_drivers-h2"&gt;How CSI drivers evolved&lt;/h2&gt; &lt;p&gt;As organizations deploy more applications for production in Kubernetes, organizations need advanced storage features that support backups and disaster recovery. Dynamic storage provisioners were traditionally limited by the small feature set of PVCs and PVs. As Kubernetes moved into mainstream IT, it needed new storage APIs.&lt;/p&gt; &lt;p&gt;Another issue with Kubernetes storage provisioners is that deploying them was a manual process, unique for each provisioner. There was no standard for which components were required on the control plane and computed nodes, and there were no troubleshooting aids.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://kubernetes-csi.github.io/docs/"&gt;Container Storage Interface&lt;/a&gt; (CSI) specification defines APIs to add and configure storage provisioners in Kubernetes clusters (Figure 1). These APIs enable the discovery of storage capabilities and define new Kubernetes resources to manage advanced storage features such as &lt;a href="https://kubernetes.io/docs/concepts/storage/volume-snapshots/"&gt;snapshots&lt;/a&gt; and &lt;a href="https://kubernetes.io/docs/concepts/storage/volume-pvc-datasource/"&gt;clones&lt;/a&gt;.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/csi.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/csi.png?itok=vRLXC-kH" width="1002" height="601" alt="A CSI can be used for access to a storage provisioner, instead of going directly from the storage class." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: A CSI can be used for access to a storage provisioner, instead of going directly from the storage class. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;Storage vendors provide CSI drivers for their storage products, preferably packaged as Operators. Kubernetes administrators install those drivers in their clusters. Administrators configure one or more storage classes using provisioners from these CSI drivers.&lt;/p&gt; &lt;p&gt;Unless you develop administrative tools, such as a backup application, you probably will not deal with the CSI API directly. You will be fine with just PVCs and storage classes. But you might want to learn some of the other storage APIs enabled by CSI to create a snapshot of a test data volume that you can revert to after each run of your integration tests.&lt;/p&gt; &lt;p&gt;Developers working in their local clusters can also use CSI capabilities by installing a CSI driver based on &lt;a href="https://github.com/metal-stack/csi-lvm"&gt;Linux LVM&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="container_storage_versus_traditional_storage-h2"&gt;Container storage vs. traditional storage&lt;/h2&gt; &lt;p&gt;Not all applications need unique storage products designed for Kubernetes. Most Network Attached Storage (NAS), Storage Area Network (SAN) vendors, and cloud providers already provide CSI drivers. Their capabilities might suffice for your needs. But the heightened demands of volatile containers that scale up and down quickly can strain many traditional storage providers.&lt;/p&gt; &lt;p&gt;Developers designed most on-premises and cloud-based stored products for a server-based world of manual labor and long provisioning times. They might support dynamic creation and destruction of virtual machine (VM) instances and disk volumes on demand, but usually not at the frequency of container changes. You could face API throttling, response time, and stability issues from your storage vendor.&lt;/p&gt; &lt;p&gt;Another difference between VM and container environments is that data does not usually move from one VM to another. Most VMs live far longer and are less "ephemeral" than containers. Kubernetes deployments put pressure on storage management APIs that your current products might not be able to handle.&lt;/p&gt; &lt;p&gt;Sometimes developers face such issues before production users because CI/CD pipelines dynamically deploy and tear down many instances of their applications, including their persistent volumes. Administrators later find other issues, such as the inability to move storage volumes between availability zones of a cloud region or a hypervisor or a hard limit on the number of LUNs they can create in a SAN appliance.&lt;/p&gt; &lt;p&gt;Sometimes it makes sense to use a traditional storage vendor as the backing storage that provides raw storage capacity to a newer storage product designed for Kubernetes. The Kubernetes-native storage can overcome the limitations of traditional storage and can even add new features, such as geo-replication.&lt;/p&gt; &lt;p&gt;One example would be the &lt;a href="https://rook.io/"&gt;Rook operator&lt;/a&gt; with AWS EBS storage or Fibre Channel LUNs. Application PVCs refer to storage classes tied to the Rook CSI driver, whereas Rook uses PVCs that refer to storage classes connected to another CSI driver.&lt;/p&gt; &lt;h2 id="wrap_up-h2"&gt;The role of the developer and Kubernetes &lt;/h2&gt; &lt;p&gt;A Kubernetes developer defines data volumes in pod resources and configures persistent volume claims (PVCs) for those volumes. Each PVC specifies, at a very high level, what the pod needs from storage, such as capacity and shareability.&lt;/p&gt; &lt;p&gt;Name a storage class on each of your PVCs if you need to distinguish between storage options with different cost, performance, or reliability characteristics. Ask your cluster administrator about the storage services connected to each available storage class on your Kubernetes clusters. The administrator might have to create a new storage class for your application.&lt;/p&gt; &lt;p&gt;Nowadays, you can expect that your Kubernetes cluster can access capable, performant, and feature-rich storage that's as capable as the storage available to any virtual machine or physical server in your data center or on your cloud. There is no reason to assume that a virtualization layer or directly attached storage would best serve your storage needs. Nor do you need "low-level" access to disk devices that bypass Kubernetes. You can assume that storage managed by Kubernetes meets your disaster recovery and high availability constraints.&lt;/p&gt; &lt;p&gt;You can expect that storage vendors provide CSI drivers and that your Kubernetes administrators install and configure the required drivers. You need to know only about your application needs and which of the available storage classes connects to storage that satisfies these needs.&lt;/p&gt; &lt;p&gt;Local developer environments can also rely on CSI drivers. There are CSI drivers for storage provisioners based on local disks and folders. That way developers can use for local testing the same manifests for local development they would deployed to a quality assurance (QA) or production environment.&lt;/p&gt; &lt;p&gt;As with bare metal and virtualized servers, your application is responsible for data integrity. No containerization, virtualization, or storage layer provides reliable data sharing and transactional recovery for your data for free. You either code it as part of your application or rely on specialized middleware such as relational databases, caching servers, and messaging servers.&lt;/p&gt; &lt;h2&gt;Try it out for yourself&lt;/h2&gt; &lt;p&gt;Now that you know the concepts of storage for Kubernetes, you probably want to get your hands dirty. The following tutorials from Red Hat Developer provide complete, step-by-step instructions for deploying a MySQL database on Kubernetes and OpenShift using persistent storage:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2020/10/22/persistent-storage-in-action-understanding-red-hat-openshifts-persistent-volume-framework#understanding_storage_architecture"&gt;Persistent storage in action: Understanding Red Hat OpenShift's persistent volume framework&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/08/11/how-maximize-data-storage-microservices-and-kubernetes-part-1-introduction#"&gt;How to maximize data storage for microservices and Kubernetes, Part 1: An introduction&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;em&gt;Thanks a lot to Andy Arnold and Greg Deffenbau for their reviews of this article.&lt;/em&gt;&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/10/06/csi-drivers-essential-kubernetes-storage" title="Why CSI drivers are essential in Kubernetes storage"&gt;Why CSI drivers are essential in Kubernetes storage&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Fernando Lozano</dc:creator><dc:date>2022-10-06T07:00:00Z</dc:date></entry><entry><title>Quarkus 2.13.1.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-2-13-1-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-2-13-1-final-released/</id><updated>2022-10-06T00:00:00Z</updated><published>2022-10-06T00:00:00Z</published><summary type="html">2.13.1.Final is the first maintenance release of the 2.13 release train. It comes with a bunch of bugfixes and documentation improvements. It is a recommended and safe upgrade for anyone already using 2.13. If you are not already using 2.13, please refer to our migration guide. Full changelog You can...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2022-10-06T00:00:00Z</dc:date></entry><entry><title>Filter content in HTML using regular expressions in grep</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/10/05/filter-content-html-using-regular-expressions-grep" /><author><name>Bob Reselman</name></author><id>4bc5a4ab-1f48-4233-b219-a86d2df9ae9a</id><updated>2022-10-05T07:00:00Z</updated><published>2022-10-05T07:00:00Z</published><summary type="html">&lt;p&gt;This article is a third in a series about executing regular expressions using the &lt;code&gt;grep&lt;/code&gt; executable that ships with &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; operating systems. The &lt;code&gt;grep&lt;/code&gt; command filters content in a file or as output from &lt;code&gt;stdout&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/articles/2022/09/14/beginners-guide-regular-expressions-grep"&gt;first article in this series&lt;/a&gt; described the basics of using metacharacters and regular characters to create regular expressions. The &lt;a href="https://developers.redhat.com/articles/2022/09/16/regex-how-quantifiers-pattern-collections-and-word-boundaries"&gt;second&lt;/a&gt; discussed working with quantifiers, pattern collections, groups, and word boundaries in regular expressions. This article uses the features described in the previous articles, along with new ones, to match and filter content in HTML files.&lt;/p&gt; &lt;p&gt;Matching and retrieving text from HTML is a common task for a broad variety of IT professionals, particularly when troubleshooting issues in web pages. Thus, being able to apply regular expressions to HTML files is a useful skill.&lt;/p&gt; &lt;p&gt;The article uses &lt;code&gt;grep&lt;/code&gt; because that won't require you to set up a particular coding environment or write any complex programming code to work with the examples of regular expressions demonstrated in this article. All you need to do is copy and paste an example onto the command line of a Linux terminal and you'll see results immediately.&lt;/p&gt; &lt;p&gt;This article is divided into three sections. The first shows you how to create regular expressions that execute against a single HTML file. The second shows you how to work with multiple HTML files. The last shows you how to use a special command-line utility named &lt;a href="https://www.pcre.org/current/doc/html/pcre2grep.html"&gt;pcre2grep&lt;/a&gt; to execute regular expressions against text split over multiple lines in one or many HTML files.&lt;/p&gt; &lt;h2&gt;Regular characters versus metacharacters&lt;/h2&gt; &lt;p&gt;A regular character represents itself in the text you're searching. Examples include the letters &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;g&lt;/code&gt;, or &lt;code&gt;t&lt;/code&gt;, or the numerical digits &lt;code&gt;3&lt;/code&gt; or &lt;code&gt;8&lt;/code&gt;. When you declare a regular character in a regular expression, the regular expression engine searches content for the declared character.&lt;/p&gt; &lt;p&gt;A metacharacter represents a group of characters or other aspects of searching. You can think of a metacharacter as a placeholder symbol. For example, the metacharacter &lt;code&gt;.&lt;/code&gt; (dot) represents "any character" and the metacharacters &lt;code&gt;\d&lt;/code&gt; represent any digit.&lt;/p&gt; &lt;h2&gt;Running regular expressions using grep against a single HTML file&lt;/h2&gt; &lt;p&gt;In this section, you'll see a variety of regular expressions executed against a single file of HTML. The HTML content used for the demonstration follows. Store the content in a file named &lt;code&gt;regex-content-01.html&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;A list of interesting and uninteresting people &lt;/title&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"&gt; &lt;/head&gt; &lt;body bgcolor="#ffffff" text="#000000"&gt; &lt;h1&gt;Interesting People&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;div id="1"&gt;Mick Jagger&lt;br&gt;mick@stones.com&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="2"&gt;Joan Jett&lt;br&gt;joan@runaways.info&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="3"&gt;John Lennon&lt;br&gt;john@beatles.io&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="4"&gt;Duck Dunn&lt;br&gt;ddunn@coolmusic.io&lt;/div&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Uninteresting People&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;div id="5"&gt;John Doe&lt;br&gt;jd@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="6"&gt;Jane Doe&lt;br&gt;jane@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="7"&gt;Uninteresting Person&lt;br&gt;up@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/body&gt; &lt;/html&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Format for using grep against a single file&lt;/h3&gt; &lt;p&gt;The format for using &lt;code&gt;grep&lt;/code&gt; against an HTML file at the command line is as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po &lt;regular_expression&gt; &lt;path/with/filename&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The elements of the syntax are as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;grep&lt;/code&gt; is the binary executable.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Po&lt;/code&gt; contains options passed to &lt;code&gt;grep&lt;/code&gt;. The &lt;code&gt;P&lt;/code&gt; option interprets the regular expression as a &lt;a href="https://perldoc.perl.org/perlre"&gt;Perl regular expression&lt;/a&gt;. The &lt;code&gt;o&lt;/code&gt; option makes &lt;code&gt;grep&lt;/code&gt; output only the text that matches, not the full lines containing it.&lt;/li&gt; &lt;li&gt;&lt;code&gt;&lt;regular_expression&gt;&lt;/code&gt; is the regular expression to execute.&lt;/li&gt; &lt;li&gt;&lt;code&gt;&lt;path/with/filename&gt;&lt;/code&gt; is the target file's location within the computer's file system, such as &lt;code&gt;~/Documents/somefile.html&lt;/code&gt;. If you provide a plain filename without a path, it refers to a file in the current working directory.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The following subsections match individual lines within a single file.&lt;/p&gt; &lt;h3&gt;Matching occurrences of a string using regular characters&lt;/h3&gt; &lt;p&gt;The following example matches occurrences of a set of regular characters in an HTML file named &lt;code&gt;regex-content-01.html&lt;/code&gt;. In this case, the regular characters form the string &lt;code&gt;people&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po 'people' regex-content-01.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;Match any occurrence of the regular characters &lt;code&gt;people&lt;/code&gt; in the file &lt;code&gt;regex-content-01.html&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;people people people&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Matching occurrences of a string using metacharacters and regular characters&lt;/h3&gt; &lt;p&gt;The following example matches occurrences of a set of metacharacters and regular characters in &lt;code&gt;regex-content-01.html&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po '@.*people' regex-content-01.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;In the file &lt;code&gt;regex-content-01.html&lt;/code&gt;, match any occurrence of the regular character &lt;code&gt;@&lt;/code&gt; followed by occurrences of any characters zero or more times (&lt;code&gt;.*&lt;/code&gt;) until the regular characters &lt;code&gt;people&lt;/code&gt; occur. &lt;/em&gt;&lt;/p&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;@uninterestingpeople @uninterestingpeople @uninterestingpeople&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;An extended version of the previous example is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po '@.*people.*\.com' regex-content-01.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;In the file &lt;code&gt;regex-content-01.html&lt;/code&gt;, match any occurrence of the regular character &lt;code&gt;@&lt;/code&gt; followed by occurrences of any characters zero or more times (&lt;code&gt;.*&lt;/code&gt;) until the regular characters &lt;code&gt;people&lt;/code&gt; occur. Then, match any characters zero or more times (&lt;code&gt;.*&lt;/code&gt;) until the regular characters &lt;code&gt;.com&lt;/code&gt; occur.&lt;/em&gt; Note that the escape metacharacter (&lt;code&gt;\&lt;/code&gt;) is used before the dot regular character (&lt;code&gt;.&lt;/code&gt;) like so: &lt;code&gt;\.&lt;/code&gt;. Using the escape metacharacter indicates that the regular expression has to process the dot as a regular character (&lt;code&gt;.&lt;/code&gt;) and &lt;em&gt;not&lt;/em&gt; as the metacharacter that means "any character."&lt;/p&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;@uninterestingpeople.com @uninterestingpeople.com @uninterestingpeople.com&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Case-insensitive match using metacharacters and regular characters&lt;/h3&gt; &lt;p&gt;The following example demonstrates how to run &lt;code&gt;grep&lt;/code&gt; using a case-insensitive regular expression, matching either uppercase or lowercase instances of characters. The key to creating a case-insensitive regular expression is to use the &lt;code&gt;-i&lt;/code&gt; option when running &lt;code&gt;grep&lt;/code&gt;. The &lt;code&gt;-i&lt;/code&gt; option indicates case-insensitive processing.&lt;/p&gt; &lt;p&gt;In this case, the regular expression returns any line that matches the regular characters &lt;code&gt;mick jagger&lt;/code&gt; in a case-insensitive manner.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Poi '.*mick jagger.*' regex-content-01.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;In the file regex-content-01.html, match any line that has zero or more occurrences of any character (&lt;code&gt;.*&lt;/code&gt;) until the regular characters &lt;code&gt;mick jagger&lt;/code&gt; occur in either lowercase or uppercase. Then match zero or more occurrences of any character (&lt;code&gt;.*&lt;/code&gt;).&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The result is the following. &lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;&lt;li&gt;&lt;div id="1"&gt;Mick Jagger&lt;br&gt;mick@stones.com&lt;/div&gt;&lt;/li&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Matching HTML list entities&lt;/h3&gt; &lt;p&gt;The following example looks for lines of text that match a string that starts with the tag &lt;code&gt;&lt;li&gt;&lt;/code&gt; and ends with the tag &lt;code&gt;&lt;/li&gt;&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po '&lt;li&gt;.*&lt;/li&gt;' regex-content-01.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;In the file &lt;code&gt;regex-content-01.html&lt;/code&gt;, match lines of text that have an occurrence of the regular characters &lt;code&gt;&lt;li&gt;&lt;/code&gt; followed by zero or more occurrences of any character (&lt;code&gt;.*&lt;/code&gt;), followed by the regular characters &lt;code&gt;&lt;/li&gt;&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;&lt;li&gt;&lt;div id="1"&gt;Mick Jagger&lt;br&gt;mick@stones.com&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="2"&gt;Joan Jett&lt;br&gt;joan@runaways.info&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="3"&gt;John Lennon&lt;br&gt;john@beatles.io&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="4"&gt;John Doe&lt;br&gt;jd@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="5"&gt;Jane Doe&lt;br&gt;jane@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="6"&gt;Uninteresting Person&lt;br&gt;&lt;a href="mailto:up@uninterestingpeople.com"&gt;up@uninterestingpeople.com&lt;/a&gt;&lt;/div&gt;&lt;/li&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Matching occurrences of a string within an HTML tag according to a range of ID values&lt;/h3&gt; &lt;p&gt;The following example defines a character class that declares a range of numerals to match within the &lt;code&gt;id&lt;/code&gt; attribute of a &lt;code&gt;&lt;div&gt;&lt;/code&gt; tag:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po '&lt;li&gt;&lt;div id="[2-4]"&gt;.*&lt;/li&gt;' regex-content-01.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;In the file &lt;code&gt;regex-content-01.html&lt;/code&gt;, match lines of text that have an occurrence of the regular characters &lt;code&gt;&lt;li&gt;&lt;div id="&lt;/code&gt; followed by any regular character that is a numeral in the range 2 to 4 (&lt;code&gt;[2-4]&lt;/code&gt;). Then match the regular characters &lt;code&gt;"&gt;&lt;/code&gt; followed by zero or more occurrences of any character (&lt;code&gt;.*&lt;/code&gt;) that are then followed by the regular characters &lt;code&gt;&lt;/li&gt;&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;&lt;li&gt;&lt;div id="2"&gt;Joan Jett&lt;br&gt;joan@runaways.info&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="3"&gt;John Lennon&lt;br&gt;john@beatles.io&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="4"&gt;John Doe&lt;br&gt;jd@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Working with multiple HTML files&lt;/h2&gt; &lt;p&gt;The following examples demonstrate how to execute regular expressions against multiple HTML files. If you want to get hands-on experience working with the examples in this section, copy and paste the following HTML into a file named &lt;code&gt;regex-content-02.html&lt;/code&gt; and save it in the same directory where you previously created &lt;code&gt;regex-content-01.html&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;A list of cool animals &lt;/title&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"&gt; &lt;/head&gt; &lt;body bgcolor="#000000" text="#ffffff"&gt; &lt;h1&gt;Interesting Pets&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;div id="1"&gt;Daffy Duck&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="2"&gt;Porky Pig&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="3"&gt;Bugs Bunny&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="4"&gt;Huckleberry Hound&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="5"&gt;Crusader Rabbit&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="6"&gt;Top Cat&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="7"&gt;Rags T. Tiger&lt;/div&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/body&gt; &lt;/html&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Formats for using grep against multiple files&lt;/h3&gt; &lt;p&gt;The format for using &lt;code&gt;grep&lt;/code&gt; against multiple HTML files at the command line is as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po &lt;regular_expression&gt; &lt;path/with/filename-01.html&gt; &lt;path/with/filename-02.html&gt; ... &lt;path/with/filename-n.html&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The elements of the syntax are as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;grep&lt;/code&gt; is the binary executable.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-Po&lt;/code&gt; contains options passed to &lt;code&gt;grep&lt;/code&gt;. The &lt;code&gt;P&lt;/code&gt; option interprets the regular expression as a &lt;a href="https://perldoc.perl.org/perlre"&gt;Perl regular expression&lt;/a&gt;. The &lt;code&gt;o&lt;/code&gt; option makes &lt;code&gt;grep&lt;/code&gt; output only the text that matches, not the full lines containing it.&lt;/li&gt; &lt;li&gt;&lt;code&gt;&lt;regular_expression&gt;&lt;/code&gt; is the regular expression to execute.&lt;/li&gt; &lt;li&gt;&lt;code&gt;&lt;path/with/filename-01.html&gt;&lt;/code&gt;, &lt;code&gt;&lt;path/with/filename-02.html&gt;&lt;/code&gt;, and &lt;code&gt;&lt;path/with/filename-n.html&gt;&lt;/code&gt; are the various target files within the computer's file system.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The format for using &lt;code&gt;grep&lt;/code&gt; with a file specification against multiple HTML files is as follows.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po &lt;regular_expression&gt; &lt;wild_card&gt;.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;code&gt;&lt;wild_card&gt;.html&lt;/code&gt; picks out filenames using wildcard characters. For example, the following declaration finds all files in the current working directory that have any filename ending with the &lt;code&gt;.html&lt;/code&gt; filename extension:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;*.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following declaration finds all files that start with the characters &lt;code&gt;regex-content-0&lt;/code&gt;, followed by any character (&lt;code&gt;?&lt;/code&gt;) and ending with the extension &lt;code&gt;.html&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;regex-content-0?.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following subsections match individual lines within multiple files.&lt;/p&gt; &lt;h3&gt;Matching a string of regular characters across multiple HTML files&lt;/h3&gt; &lt;p&gt;The following example matches all strings of regular characters &lt;code&gt;Duck&lt;/code&gt; that occur in all files in the current directory that have file names that end with the extension &lt;code&gt;.html&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po 'Duck' *.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;Match any occurrence of the regular characters &lt;code&gt;Duck&lt;/code&gt; in all files in the current directory that have filenames that end with the extension &lt;code&gt;.html&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;regex-content-01.html:Duck regex-content-02.html:Duck&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Matching lines of text across multiple HTML files according to metacharacters and regular characters&lt;/h3&gt; &lt;p&gt;The following command matches a string plus all surrounding text on the same line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po '.*Duck.*' *.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;In all files in the current directory that have file names that end with the extension &lt;code&gt;.html&lt;/code&gt;, match lines of text that have zero or more occurrences of any character (&lt;code&gt;.*&lt;/code&gt;), then the regular characters &lt;code&gt;Duck&lt;/code&gt;, followed by zero or more occurrences of any character (&lt;code&gt;.*&lt;/code&gt;).&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The result is the following.&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;regex-content-01.html: &lt;li&gt;&lt;div id="4"&gt;Duck Dunn&lt;br&gt;ddunn@coolmusic.io&lt;/div&gt;&lt;/li&gt; regex-content-02.html: &lt;li&gt;&lt;div id="1"&gt;Daffy Duck&lt;/div&gt;&lt;/li&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Matching occurrences of characters within an HTML tag across multiple HTML files&lt;/h3&gt; &lt;p&gt;The following example finds all characters between the &lt;code&gt;&lt;li&gt;&lt;/code&gt; and &lt;code&gt;&lt;/li&gt;&lt;/code&gt; HTML tags in all files in the current directory that have file names that end with the extension &lt;code&gt;.html&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po '&lt;li&gt;.*&lt;/li&gt;' *.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;In all files in the current directory that have file names that end with the extension &lt;code&gt;.html&lt;/code&gt;, match lines of text that have an occurrence of the regular characters &lt;code&gt;&lt;li&gt;&lt;/code&gt; followed by zero or more occurrences of any character (&lt;code&gt;.*&lt;/code&gt;), followed by the regular characters &lt;code&gt;&lt;/li&gt;&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;regex-content-01.html:&lt;li&gt;&lt;div id="1"&gt;Mick Jagger&lt;br&gt;mick@stones.com&lt;/div&gt;&lt;/li&gt; regex-content-01.html:&lt;li&gt;&lt;div id="2"&gt;Joan Jett&lt;br&gt;joan@runaways.info&lt;/div&gt;&lt;/li&gt; regex-content-01.html:&lt;li&gt;&lt;div id="3"&gt;John Lennon&lt;br&gt;john@beatles.io&lt;/div&gt;&lt;/li&gt; regex-content-01.html:&lt;li&gt;&lt;div id="4"&gt;Duck Dunn&lt;br&gt;ddunn@coolmusic.io&lt;/div&gt;&lt;/li&gt; regex-content-01.html:&lt;li&gt;&lt;div id="5"&gt;John Doe&lt;br&gt;jd@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; regex-content-01.html:&lt;li&gt;&lt;div id="6"&gt;Jane Doe&lt;br&gt;jane@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; regex-content-01.html:&lt;li&gt;&lt;div id="7"&gt;Uninteresting Person&lt;br&gt;up@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; regex-content-02.html:&lt;li&gt;&lt;div id="1"&gt;Daffy Duck&lt;/div&gt;&lt;/li&gt; regex-content-02.html:&lt;li&gt;&lt;div id="2"&gt;Porky Pig&lt;/div&gt;&lt;/li&gt; regex-content-02.html:&lt;li&gt;&lt;div id="3"&gt;Bugs Bunny&lt;/div&gt;&lt;/li&gt; regex-content-02.html:&lt;li&gt;&lt;div id="4"&gt;Huckleberry Hound&lt;/div&gt;&lt;/li&gt; regex-content-02.html:&lt;li&gt;&lt;div id="5"&gt;Crusader Rabbit&lt;/div&gt;&lt;/li&gt; regex-content-02.html:&lt;li&gt;&lt;div id="6"&gt;Top Cat&lt;/div&gt;&lt;/li&gt; regex-content-02.html:&lt;li&gt;&lt;div id="7"&gt;Rags T. Tiger&lt;/div&gt;&lt;/li&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Matching occurrences of specific characters within an HTML tag across multiple HTML files&lt;/h3&gt; &lt;p&gt;The following command finds &lt;code&gt;&lt;li&gt;&lt;/code&gt; entities containing a particular string, &lt;code&gt;Duck&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po '&lt;li&gt;.*Duck.*&lt;/li&gt;' *.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;In all files in the current directory that have file names that end with the extension &lt;code&gt;.html&lt;/code&gt;, match lines of text that have an occurrence of the regular characters &lt;code&gt;&lt;li&gt;&lt;/code&gt; followed by zero or more occurrences of any character (&lt;code&gt;.*&lt;/code&gt;), then the regular characters Duck, followed by zero or more occurrences of any character (&lt;code&gt;.*&lt;/code&gt;), which are then followed by the regular characters &lt;code&gt;&lt;/li&gt;&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;regex-content-01.html:&lt;li&gt;&lt;div id="4"&gt;Duck Dunn&lt;br&gt;ddunn@coolmusic.io&lt;/div&gt;&lt;/li&gt; regex-content-02.html:&lt;li&gt;&lt;div id="1"&gt;Daffy Duck&lt;/div&gt;&lt;/li&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Working across multiple lines of HTML&lt;/h2&gt; &lt;p&gt;One of the shortcomings of the &lt;code&gt;grep&lt;/code&gt; command is that it does not allow you to execute a regular expression across multiple line breaks in text. For example, consider the file &lt;code&gt;regex-content-02.html&lt;/code&gt;, which has the following snippet of HTML:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;&lt;title&gt;A list of cool animals &lt;/title&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following regular expression in a &lt;code&gt;grep&lt;/code&gt; command will &lt;em&gt;not&lt;/em&gt; match the &lt;code&gt;&lt;title&gt;...&lt;/title&gt;&lt;/code&gt; content in the previous snippet, because &lt;code&gt;grep&lt;/code&gt; does not match line break metacharacters such as &lt;code&gt;\n&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -Po '&lt;title.*\n.*&lt;/title&gt;' regex-content-02.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Other dialects of regular expressions, such as those found in JavaScript, Java, PHP, and C#, can work with line breaks, but &lt;code&gt;grep&lt;/code&gt; cannot. In order to do matching across multiple lines of text at the command line, you need to use &lt;code&gt;pcre2grep&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Installing pcre2grep&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;pcre2grep&lt;/code&gt; executable typically needs to be installed by an administrator on a Linux computer. The command does not ship by default.&lt;/p&gt; &lt;p&gt;Run the following commands to install &lt;code&gt;pcre2grep&lt;/code&gt; on a computer running &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt;, Fedora, or CentOS Stream:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ sudo dnf update $ sudo dnf install pcre2-tools -y&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Run the following commands to install &lt;code&gt;pcre2grep&lt;/code&gt; on a computer running Ubuntu or another system based on Debian:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ sudo apt update $ sudo apt-get install pcre2-utils -y&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once you have &lt;code&gt;pcre2grep&lt;/code&gt; installed, you can run the following examples against the HTML files you installed previously.&lt;/p&gt; &lt;h3&gt;Finding the content between HTML tags that are defined over two lines&lt;/h3&gt; &lt;p&gt;The following example uses &lt;code&gt;pcre2grep&lt;/code&gt; to match all content that covers two lines in a case-insensitive manner between &lt;code&gt;&lt;title&gt;&lt;/code&gt; and &lt;code&gt;&lt;/title&gt;&lt;/code&gt; tags, including the tags themselves, within all HTML files in the current directory.&lt;/p&gt; &lt;p&gt;The example uses the &lt;code&gt;-Mi&lt;/code&gt; options with &lt;code&gt;pcre2grep&lt;/code&gt;. The &lt;code&gt;M&lt;/code&gt; option allows matching over multiple lines. The &lt;code&gt;i&lt;/code&gt; option conducts matches in a case-insensitive manner. The example uses the metacharacters &lt;code&gt;\n&lt;/code&gt; to indicate a line break:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ pcre2grep -Mi '&lt;title.*\n.*&lt;\title&gt;' *.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;Match the contents in any file in the current directory that has the extension &lt;code&gt;.html&lt;/code&gt;. Search the file contents to match the characters &lt;code&gt;&lt;title&lt;/code&gt; followed by zero or more occurrences of any character (&lt;code&gt;.*&lt;/code&gt;) until the line break metacharacters (&lt;code&gt;\n&lt;/code&gt;) occur. Then continue matching occurrences of any character (&lt;code&gt;.*&lt;/code&gt;) until the regular characters &lt;code&gt;&lt;/title&gt;&lt;/code&gt; occur.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;regex-content-01.html: &lt;title&gt;A list of interesting and uninteresting people &lt;/title&gt; regex-content-02.html: &lt;title&gt;A list of cool animals &lt;/title&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The example shown above matches only a single line break. The regular expression will not find a match if content including the &lt;code&gt;&lt;title&gt;&lt;/code&gt; and &lt;code&gt;&lt;/title&gt;&lt;/code&gt; tags covers more than two lines, like so:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;&lt;title&gt; A list of cool animals &lt;/title&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The way to address the problem is to use the metacharacters (&lt;code&gt;?s&lt;/code&gt;) so the regular expression interprets the dot metacharacter (&lt;code&gt;.&lt;/code&gt;) to include line breaks, as shown in the next example.&lt;/p&gt; &lt;h3&gt;Finding the content between unordered list tags in HTML files using (?s)&lt;/h3&gt; &lt;p&gt;The following example prepends the metacharacters (&lt;code&gt;?s&lt;/code&gt;) to the regular expression to make it process the dot metacharacter (&lt;code&gt;.&lt;/code&gt;) to include line breaks as "any character":&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ pcre2grep -Mo '(?s)&lt;ul.+ul&gt;' *.html&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The logic that the regular expression executes is as follows: &lt;em&gt;Match the contents in any file in the current directory that has the extension &lt;code&gt;.html&lt;/code&gt;. The "any character" wildcard metacharacter (&lt;code&gt;.&lt;/code&gt;) can include line breaks as indicated by the metacharacters &lt;code&gt;(?s)&lt;/code&gt; at the start of the regular expression. Start by matching an occurrence of the regular characters &lt;code&gt;&lt;ul&lt;/code&gt; , followed by one or many occurrences of any character including line breaks (&lt;code&gt;.+&lt;/code&gt;), followed by an occurrence of the regular characters &lt;code&gt;ul&gt;&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="java"&gt;regex-content-01.html:&lt;ul&gt; &lt;li&gt;&lt;div id="1"&gt;Mick Jagger&lt;br&gt;mick@stones.com&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="2"&gt;Joan Jett&lt;br&gt;joan@runaways.info&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="3"&gt;John Lennon&lt;br&gt;john@beatles.io&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="4"&gt;Duck Dunn&lt;br&gt;ddunn@coolmusic.io&lt;/div&gt;&lt;/li&gt; &lt;/ul&gt; regex-content-01.html:&lt;ul&gt; &lt;li&gt;&lt;div id="5"&gt;John Doe&lt;br&gt;jd@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="6"&gt;Jane Doe&lt;br&gt;jane@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="7"&gt;Uninteresting Person&lt;br&gt;up@uninterestingpeople.com&lt;/div&gt;&lt;/li&gt; &lt;/ul&gt; regex-content-02.html:&lt;ul&gt; &lt;li&gt;&lt;div id="1"&gt;Daffy Duck&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="2"&gt;Porky Pig&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="3"&gt;Bugs Bunny&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="4"&gt;Huckleberry Hound&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="5"&gt;Crusader Rabbit&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="6"&gt;Top Cat&lt;/div&gt;&lt;/li&gt; &lt;li&gt;&lt;div id="7"&gt;Rags T. Tiger&lt;/div&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Putting it all together&lt;/h2&gt; &lt;p&gt;Filtering content in HTML files is a useful skill for any IT professional working on the web. Whether you're a front-end developer trying to debug a misbehaving web page or a system administrator looking for particular words or phrases in directories full of HTML files, being able to execute regular expressions using &lt;code&gt;grep&lt;/code&gt; or across multiple lines of text using &lt;code&gt;prce2grep&lt;/code&gt; is valuable.&lt;/p&gt; &lt;p&gt;The techniques covered in this article are but an introduction. There's a lot more to learn. Still, the basics presented here will provide a solid foundation upon which to move forward in your journey toward mastery of regular expressions.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/10/05/filter-content-html-using-regular-expressions-grep" title="Filter content in HTML using regular expressions in grep"&gt;Filter content in HTML using regular expressions in grep&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Bob Reselman</dc:creator><dc:date>2022-10-05T07:00:00Z</dc:date></entry><entry><title type="html">Comparing Choices in DMN Modeling</title><link rel="alternate" href="https://blog.kie.org/2022/10/comparing-choices-in-modeling-dmn.html" /><author><name>Eder Ignatowicz</name></author><id>https://blog.kie.org/2022/10/comparing-choices-in-modeling-dmn.html</id><updated>2022-10-04T05:00:00Z</updated><content type="html">Recently in a , Keith Swenson, VP of R&amp;amp;D Fujitsu America and former leader of the DMN “Technical Compatibility Kit,” did a comparative analysis between free DMN modeling alternatives. The author compared TrisoTech DMN Modeler, Camunda, Red Hat Drools Workbench, and our beloved . As the results are interesting, I’ve decided to share them in a blog post. LITTLE BACKGROUND: KIE SANDBOX AND DMN ‘RUNNER’ Started with a prototype in late 2020, aiming to explore ways to augment the developer authoring experience for BPMN and DMN assets; gradually got traction and became an integrated part of our Tooling experience. Check out this for a walkthrough of the top features of KIE Sandbox. Focusing on a seamless authoring experience and an instantaneous feedback loop for DMN models, the DMN runner was mid-2021, and quickly became one of my favorite innovations on Tooling. Using a fast and automatic form generation and evaluation based on DMN models, DMN runner allows users to quickly try and experiment with their DMN runner in authoring, emulating an experience similar to authoring a spreadsheet like Excel or Google Docs. COMPARING CHOICES IN MODELING DMN In a recent , Keith Swenson provided the following feedback from our tools: &gt; What is particularly impressive is the DMN test capability. To get it to run, &gt; you need to download and start the KIE Sandbox Extended Services, which ran &gt; without a hitch. The web UI automatically noticed that the engine was &gt; installed. Then, it would automatically generate forms for inputting the data. &gt; Most impressive was that it can handle structured data records and arrays, &gt; even arrays of structured records. The output appears in the next column over. &gt; The complex table and list commands all ran. It is hard for me to really &gt; express how great it was after days of trying to get various combinations to &gt; work, to find an environment where everything ran without a problem. &gt; So, if you want practical experience with DMN models and running the models, &gt; go right to KIE Sandbox. It works. &gt; – Keith Swenson The author also summarizes that among other competitors, KIE Sandbox is the “best all around tool for a DMN practitioner, and built on RedHat so certainly compatible with that.” Keith Swenson, our tooling team, would like to thank you for the feedback, and we are looking forward to ways to improve even more our Tooling! The post appeared first on .</content><dc:creator>Eder Ignatowicz</dc:creator></entry><entry><title type="html">KIE Tools Highlights &amp;#8211; Q3</title><link rel="alternate" href="https://blog.kie.org/2022/10/kie-tools-highlights-q3.html" /><author><name>Eder Ignatowicz</name></author><id>https://blog.kie.org/2022/10/kie-tools-highlights-q3.html</id><updated>2022-10-03T05:00:00Z</updated><content type="html">Some days ago, we just launched KIE Tools and wrap-up the deliverables of our team for the third quarter. The main goal of this milestone was to expand the Serverless Workflow tooling to provide the best developer experience for the Serverless Logic ecosystem, with highlights to the new Serverless Workflow visualization! This post will give a quick overview of the most important deliverables of this quarter. I hope you enjoy it! MODERNIZE SERVERLESS WORKFLOW VISUALIZATION In partnership with Red Hat UX Team, we are happy to announce that we just released a new diagram visualizer for the Serverless Workflow based on . This new visualization improves the user experience authoring Serverless Workflows, with a much better look and feel, and a lot of additional features like state navigation, error handling, and automatic workflow reloading. See this for full details. SERVERLESS WORKFLOW PLUG-IN FOR KNATIVE CLI Serverless Workflow provides a plug-in named kn-plugin-workflow for Knative CLI, enabling you to quickly set up a local workflow project using the command line. See our for more information. Our plug-in is now included by default in the client, allowing users of this CLI to create and use workflow commands without the need to install any additional plug-in. CUSTOM DASHBOARDS ON DEV UI Besides our default Dashboard on Quarkus Dev UI, users now can have custom dashboards based on . Check out this video: DASHBUILDER SAMPLES Almost every week, we push new samples from our Dashbuilder samples repository. This month’s highlight is William’s , which allows us to visualize data from Quarkus or even embed dashboards in my Quarkus application. You can check it running live . KOGITO SERVERLESS WORKFLOW GUIDES Our team also wrote a lot of guides to Kogito Serverless Workflow . You can start exploring by checking out the . WHAT IS IN PROGRESS? We have several initiatives in R&amp;amp;D and in progress, including: * Expand Knative developer experience, allowing users to create, run and deploy single file workflows without Java dependencies; * Reach feature parity between JSON and YAML text editing experiences, enabling a rich edit experience on YAML-based workflows; * Native integration of Serverless workflow with Ansible, Kaoto and RHODS; * More improvements for Dev UI; * Standalone embeddable Serverless Workflow editor; * Improve auto completion experience, to make it easier to invoke a service or orchestrate and event, i.e. to create specific states like operation and async; * Serverless Logic Web Tools UX Redesign; * Dashbuilder VS Code extension; THANK YOU TO EVERYONE INVOLVED! I would like to thank everyone involved with this release, from the excellent KIE Tooling Engineers to the lifesavers QEs and the UX people that help us look awesome! The post appeared first on .</content><dc:creator>Eder Ignatowicz</dc:creator></entry><entry><title type="html">Eclipse Vert.x 4.3.4 released!</title><link rel="alternate" href="https://vertx.io/blog/eclipse-vert-x-4-3-4" /><author><name>Julien Viet</name></author><id>https://vertx.io/blog/eclipse-vert-x-4-3-4</id><updated>2022-10-03T00:00:00Z</updated><content type="html">Eclipse Vert.x version 4.3.4 has just been released. It fixes quite a few bugs that have been reported by the community and provides a couple of features. In addition it provides support for virtual threads incubation project.</content><dc:creator>Julien Viet</dc:creator></entry><entry><title>Perform inference using Intel OpenVINO Model Server on OpenShift</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/09/30/perform-inference-using-intel-openvino-model-server-openshift" /><author><name>Audrey Reznik</name></author><id>61b1b545-e963-4cef-a514-7ea1507a17fd</id><updated>2022-09-30T07:00:00Z</updated><published>2022-09-30T07:00:00Z</published><summary type="html">&lt;p&gt;Model servers, as illustrated in Figure 1, are very convenient for AI applications. They act as &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt; and can abstract the entirety of inference execution, making them agnostic to the training framework and hardware. They also offer easy scalability and efficient resource utilization.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig1_11.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig1_11.png?itok=2HLp0Sa1" width="547" height="197" alt="Diagram showing a model server as part of an AI application" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: A model server as part of an AI application. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; are optimal places for deploying model servers. However, managing them directly can be a complex task in a large-scale environment. In this article, you'll learn how the OpenVINO Model Server Operator can make it straightforward.&lt;/p&gt; &lt;h2&gt;Operator installation&lt;/h2&gt; &lt;p&gt;The operator can be easily installed from the OpenShift console. Just navigate to the &lt;strong&gt;OperatorHub&lt;/strong&gt; menu (Figure 2), search for OpenVINO™ Toolkit Operator, then click the Install button.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig2_7.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig2_7.png?itok=h5ZyukuW" width="600" height="588" alt="Screenshot showing the installation of the OpenVINO Toolkit Operator" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Install the OpenVINO Toolkit Operator. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;h2&gt;Deploying an OpenVINO Model Server in OpenShift&lt;/h2&gt; &lt;p&gt;Creating a new instance of the model server is easy in the OpenShift console interface (Figure 3). Click the &lt;strong&gt;Create ModelServer&lt;/strong&gt; and then fill in the interactive form.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig3_4.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig3_4.png?itok=eIwPJSG9" width="600" height="166" alt="Screenshot showing the creation of a Model Server" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Create a Model Server &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;The default exemplary parameters deploy a fully functional model server with the well-known image classification model ResNet-50. This model is available in the public cloud for anyone to use. Why are we using this model? Because it saves us time from creating our own image classification model from scratch.&lt;/p&gt; &lt;p&gt;A bit more information on the ResNet-50 model just in case you have never heard of it before: The model is a pre-trained deep learning model for image classification of the &lt;em&gt;convolutional neural network,&lt;/em&gt; which is a class of deep neural networks most commonly applied to analyzing images. The &lt;em&gt;50&lt;/em&gt; in the name represents the model being 50 layers deep. The model is trained on a million images in a thousand categories from the &lt;a href="https://www.image-net.org/"&gt;ImageNet database&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you'd rather use the command-line interface (CLI) instead of the OpenShift console, you would use a command like this:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;oc apply -f https://raw.githubusercontent.com/openvinotoolkit/operator/main/config/samples/intel_v1alpha1_ovms.yaml&lt;/code&gt; &lt;/pre&gt; &lt;p&gt;More complex deployments with &lt;a href="https://docs.openvino.ai/latest/ovms_docs_multiple_models.html"&gt;multiple models&lt;/a&gt; or &lt;a href="https://docs.openvino.ai/latest/ovms_docs_dag.html"&gt;DAG pipelines&lt;/a&gt; can also be deployed fairly easily by adding a config.json file into a configmap and linking it with the &lt;code&gt;ModelServer&lt;/code&gt; resource.&lt;/p&gt; &lt;p&gt;In this article, let's check the usage with the default Resnet model. While deployed, it will create the resources shown in Figure 4.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig4_5.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig4_5.png?itok=z1chFpmN" width="600" height="362" alt="Screenshot showing resources for model deployment" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Resources for model deployment. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;h2&gt;How to run inferences from ovmsclient&lt;/h2&gt; &lt;p&gt;In this demonstration, let's create a pod in our OpenShift cluster that will act as a client. This can be done from the OpenShift console or from the CLI. We'll use a &lt;code&gt;python:3.8.13&lt;/code&gt; image with a &lt;code&gt;sleep infinity&lt;/code&gt; command just to have a place for an interactive shell. We will submit a jpeg image of a zebra and see if the image can be identified by our model.&lt;/p&gt; &lt;pre&gt; &lt;code&gt;oc create deployment client-test --image=python:3.8.13 -- sleep infinity oc exec -it $(oc get pod -o jsonpath="{.items[0].metadata.name}" -1 app=client-test) -- bash&lt;/code&gt; &lt;/pre&gt; &lt;p&gt;From the interactive shell inside the client container, let's quickly test connectivity with the model server and check the model parameters.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; curl http://model-server-sample-ovms:8081/v1/config { "resnet" : { "model_version_status": [ { "version": "1", "state": "AVAILABLE", "status": { "error_code": "OK", "error_message": "OK" } } } } &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Other REST API calls are described in the &lt;a href="https://docs.openvino.ai/2022.1/ovms_docs_server_api.html"&gt;OpenVINO API reference guide&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Now let's use the Python library &lt;code&gt;ovmsclient&lt;/code&gt; to run the inference request:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; python3 -m venv /tmp/venv source /tmp/venv/bin/activate pip install ovmsclient &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;We'll download a zebra picture to test out the classification:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;curl https://raw.githubusercontent.com/openvinotoolkit/model_server/main/demos/common/static/images/zebra.jpeg -o /tmp/zebra.jpeg &lt;/code&gt; &lt;/pre&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig5.jpg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig5.jpg?itok=63Rf7-mN" width="336" height="224" alt="Image of a zebra" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Picture of a zebra used for prediction. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;Below are the Python commands that will display the model metadata using the &lt;code&gt;ovmsclient&lt;/code&gt; library:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; from ovmsclient import make_grpc_client client = make_grpc_client("model-server-sample-ovms:8080") model_metadata = client.get_model_metadata(model_name="resnet") print(model_metadata) &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Those commands produce the following response:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; {'model_version': 1, 'inputs': {'map/TensorArrayStack/TensorArrayGatherV3:0': {'shape': [-1, -1, -1, -1], 'dtype': 'DT_FLOAT'}}, 'outputs': {'softmax_tensor': {'shape': [-1, 1001], 'dtype': 'DT_FLOAT'}}} &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Now you can create a Python script with basic client content:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; cat &gt;&gt; /tmp/predict.py &lt;&lt;EOL from ovmsclient import make_grpc_client import numpy as np client = make_grpc_client("model-server-sample-ovms:8080") with open("/tmp/zebra.jpeg", "rb") as f: data = f.read() inputs = {"map/TensorArrayStack/TensorArrayGatherV3:0": data} results = client.predict(inputs=inputs, model_name="resnet") print("Detected class:", np.argmax(results)) EOL python /tmp/predict.py Detected class: 341 &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Based on the ImageNet database which contains a thousand classes, our zebra image was matched to their zebra image, which happens to have the class ID 341 associated with it. This means that our image was successfully matched and is confirmed as a zebra image!&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;As you've seen, the OpenVINO Model Server can be easily deployed and used in OpenShift and Kubernetes environments. In this article, you learned how to run predictions using the &lt;code&gt;ovmsclient&lt;/code&gt; Python library.&lt;/p&gt; &lt;p&gt;You can &lt;a href="https://github.com/openvinotoolkit/operator"&gt;learn more about the Operator&lt;/a&gt; and check out &lt;a href="https://docs.openvino.ai/2022.1/ovms_docs_demos.html"&gt;other demos with OpenVINO Model Server&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/09/30/perform-inference-using-intel-openvino-model-server-openshift" title="Perform inference using Intel OpenVINO Model Server on OpenShift"&gt;Perform inference using Intel OpenVINO Model Server on OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Audrey Reznik</dc:creator><dc:date>2022-09-30T07:00:00Z</dc:date></entry></feed>
